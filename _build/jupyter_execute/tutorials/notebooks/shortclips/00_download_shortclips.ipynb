{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Download the data set\n",
    "\n",
    "In this script, we download the data set from Wasabi or GIN. No account is\n",
    "required.\n",
    "\n",
    "## Cite this data set\n",
    "\n",
    "This tutorial is based on publicly available data [published on GIN](https://gin.g-node.org/gallantlab/shortclips). If you publish any work using\n",
    "this data set, please cite the original publication [1]_, and the data set\n",
    "[2]_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'voxelwise_tutorials'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# path of the data directory\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvoxelwise_tutorials\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_data_home\n\u001b[0;32m      3\u001b[0m directory \u001b[38;5;241m=\u001b[39m get_data_home(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshortclips\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(directory)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'voxelwise_tutorials'"
     ]
    }
   ],
   "source": [
    "# path of the data directory\n",
    "from voxelwise_tutorials.io import get_data_home\n",
    "directory = get_data_home(dataset=\"shortclips\")\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only use the first subject in this tutorial, but you can run the same\n",
    "analysis on the four other subjects. Uncomment the lines in ``DATAFILES`` to\n",
    "download more subjects.\n",
    "\n",
    "We also skip the stimuli files, since the dataset provides two preprocessed\n",
    "feature spaces to perform voxelwise modeling without requiring the original\n",
    "stimuli.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from voxelwise_tutorials.io import download_datalad\n",
    "\n",
    "DATAFILES = [\n",
    "    \"features/motion_energy.hdf\",\n",
    "    \"features/wordnet.hdf\",\n",
    "    \"mappers/S01_mappers.hdf\",\n",
    "    # \"mappers/S02_mappers.hdf\",\n",
    "    # \"mappers/S03_mappers.hdf\",\n",
    "    # \"mappers/S04_mappers.hdf\",\n",
    "    # \"mappers/S05_mappers.hdf\",\n",
    "    \"responses/S01_responses.hdf\",\n",
    "    # \"responses/S02_responses.hdf\",\n",
    "    # \"responses/S03_responses.hdf\",\n",
    "    # \"responses/S04_responses.hdf\",\n",
    "    # \"responses/S05_responses.hdf\",\n",
    "    # \"stimuli/test.hdf\",\n",
    "    # \"stimuli/train_00.hdf\",\n",
    "    # \"stimuli/train_01.hdf\",\n",
    "    # \"stimuli/train_02.hdf\",\n",
    "    # \"stimuli/train_03.hdf\",\n",
    "    # \"stimuli/train_04.hdf\",\n",
    "    # \"stimuli/train_05.hdf\",\n",
    "    # \"stimuli/train_06.hdf\",\n",
    "    # \"stimuli/train_07.hdf\",\n",
    "    # \"stimuli/train_08.hdf\",\n",
    "    # \"stimuli/train_09.hdf\",\n",
    "    # \"stimuli/train_10.hdf\",\n",
    "    # \"stimuli/train_11.hdf\",\n",
    "]\n",
    "\n",
    "source = \"https://gin.g-node.org/gallantlab/shortclips\"\n",
    "\n",
    "for datafile in DATAFILES:\n",
    "    local_filename = download_datalad(datafile, destination=directory,\n",
    "                                      source=source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    ".. [1] Huth, A. G., Nishimoto, S., Vu, A. T., & Gallant, J. L. (2012). A\n",
    "    continuous semantic space describes the representation of thousands of\n",
    "    object and action categories across the human brain. Neuron, 76(6),\n",
    "    1210-1224.\n",
    "\n",
    ".. [2] Huth, A. G., Nishimoto, S., Vu, A. T., Dupr√© la Tour, T., & Gallant, J. L. (2022).\n",
    "    Gallant Lab Natural Short Clips 3T fMRI Data. http://dx.doi.org/10.12751/g-node.vy1zjd\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}